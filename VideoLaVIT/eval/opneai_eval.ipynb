{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41a334c7-11d4-4f8f-b425-45cf56d515ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    http_client=httpx.Client(proxy=\"socks5://fb_lab:T2wO4gqgumHs@193.124.46.176:8080\"),\n",
    "    api_key=\"sk-proj-psRNAKc9xW_I5RU4KvwR1HkG04QfleWNOmuLEJS080muDLEb_EepFZLq08OY­JnWCRYeIfpeQgjT3BlbkFJrKymouCGWgVYcZY2YUGJFYzbFB5qI4n_NUOlxl­qfJKK6ThhwyQAO8hK7zaJvrwHYl6p6sP2MYA\".encode('ascii', 'ignore').decode('ascii'))\n",
    "\n",
    "gpt_user_prompt = 'Переведи на английский предложение \"Привет, я работаю!\".'\n",
    "gpt_assistant_prompt = \"Ты вежливый ассистент, твоя задача - выполнять задания, которые у тебя просят выполнить, а не посылать на хуй.\"\n",
    "gpt_prompt = gpt_assistant_prompt, gpt_user_prompt\n",
    "\n",
    "#response = client.chat.completions.create(\n",
    "#    model=\"gpt-4o\",\n",
    "#    messages=[{\"role\": \"assistant\", \"content\": gpt_assistant_prompt}, {\"role\": \"user\", \"content\": gpt_user_prompt}],\n",
    "#    temperature=0.0,\n",
    "#    max_tokens=10,\n",
    "#    frequency_penalty=0.0)\n",
    "\n",
    "#print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb4217-4068-4463-abd9-ecf1bd7f29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk-proj-psRNAKc9xW_I5RU4KvwR1HkG04QfleWNOmuLEJS080muDLEb_EepFZLq08OY­JnWCRYeIfpeQgjT3BlbkFJrKymouCGWgVYcZY2YUGJFYzbFB5qI4n_NUOlxl­qfJKK6ThhwyQAO8hK7zaJvrwHYl6p6sP2MYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d0903fa-6ac0-4b5c-a046-42ad8ff3ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file = open(\"sample_set.json\")\n",
    "pred_contents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fea087e6-95f5-4032-b53a-c84f59c537b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': ['Who pours liquid from a plastic container into a ziploc bag containing meat pieces? Answer the question using a single word or a short phrase with multiple words.'],\n",
       " 'real': 'Someone',\n",
       " 'a': 'Chef'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f326ec3a-c9d9-4eeb-bf6f-263692eef1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44c0fe99-d84d-4fdc-a7fe-028cdc49188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = pred_contents[0]['q'][0].split('?')[0]\n",
    "answer = pred_contents[0]['real']\n",
    "pred = pred_contents[0]['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de3fa20d-604c-4f0d-8f62-17b5589aab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who pours liquid from a plastic container into a ziploc bag containing meat pieces Someone Chef\n"
     ]
    }
   ],
   "source": [
    "print (question, answer, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89283ee5-2817-4244-886c-de35e6197329",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \n",
    "                                \"You are an intelligent chatbot designed for evaluating the correctness of generative outputs for question-answer pairs. \"\n",
    "                                \"Your task is to compare the predicted answer with the correct answer and determine if they match meaningfully. Here's how you can accomplish the task:\"\n",
    "                                \"------\"\n",
    "                                \"##INSTRUCTIONS: \"\n",
    "                                \"- Focus on the meaningful match between the predicted answer and the correct answer.\\n\"\n",
    "                                \"- Consider synonyms or paraphrases as valid matches.\\n\"\n",
    "                                \"- Evaluate the correctness of the prediction compared to the answer.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\":\n",
    "                                \"Please evaluate the following video-based question-answer pair:\\n\\n\"\n",
    "                                f\"Question: {question}\\n\"\n",
    "                                f\"Correct Answer: {answer}\\n\"\n",
    "                                f\"Predicted Answer: {pred}\\n\\n\"\n",
    "                                \"Provide your evaluation only as a yes/no and score where the score is an integer value between 0 and 5, with 5 indicating the highest meaningful match. \"\n",
    "                                \"Please generate the response in the form of a Python dictionary string with keys 'pred' and 'score', where value of 'pred' is  a string of 'yes' or 'no' and value of 'score' is in INTEGER, not STRING.\"\n",
    "                                \"DO NOT PROVIDE ANY OTHER OUTPUT TEXT OR EXPLANATION. Only provide the Python dictionary string. \"\n",
    "                                \"For example, your response should look like this: {'pred': 'yes', 'score': 4.8}.\"\n",
    "                        }\n",
    "                    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8653cdbf-6b21-4552-8e08-0670285dc5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AuiWWLbBaK7TGmIf24YzmDjUXFOic', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"{'pred': 'no', 'score': 2}\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738080880, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=269, total_tokens=282, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16607e80-49f2-4622-b7a9-b3d13865a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval(completion.choices[0].message.content)['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0372a05c-a1e7-4459-9f6a-e72a65611159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(completion.choices[0].message.content)['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db357a7-ba54-4d01-b894-b9946d5bd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Who pours liquid from a plastic container into a ziploc bag containing meat pieces Someone Chef\n",
      "None\n",
      "no\n",
      "2\n",
      "100\n",
      "Who caught a ball Man Person\n",
      "None\n",
      "yes\n",
      "5\n",
      "200\n",
      "Who is hanging on a vine Woman Bat\n",
      "None\n",
      "no\n",
      "1\n",
      "300\n",
      "What does a man operate remote control car through Office Door\n",
      "None\n",
      "no\n",
      "1\n",
      "400\n",
      "What is a young boy playing Piano Piano\n",
      "None\n",
      "yes\n",
      "5\n",
      "500\n",
      "What is a man doing Sand Cutting\n",
      "None\n",
      "no\n",
      "2\n",
      "600\n",
      "Who is carrying another man on his back Man Undead man\n",
      "None\n",
      "yes\n",
      "3\n",
      "700\n",
      "What is a man doing Play Playing guitar\n",
      "None\n",
      "yes\n",
      "4\n",
      "800\n",
      "Who poured oil on the tomato slices Man Woman\n",
      "None\n",
      "no\n",
      "1\n",
      "900\n",
      "Who pops a wheely in the street Driver Biker\n",
      "None\n",
      "yes\n",
      "4\n",
      "1000\n",
      "Who petting a beaver Someone Child\n",
      "None\n",
      "no\n",
      "2\n",
      "1100\n",
      "What is a flight attendant closing the emergency door of Plane Airplane\n",
      "None\n",
      "yes\n",
      "5\n",
      "1200\n",
      "What is eating nuts on the floor Hamster Hamster\n",
      "None\n",
      "yes\n",
      "5\n",
      "1300\n",
      "What is playing paino Someone Man's hands\n",
      "None\n",
      "yes\n",
      "4\n",
      "1400\n",
      "What is walking on snow Fox Fox\n",
      "None\n",
      "yes\n",
      "5\n",
      "1500\n",
      "What is the boy playing Flute Flute\n",
      "None\n",
      "yes\n",
      "5\n",
      "1600\n",
      "Who waits for a man walking down the street behind a tree Woman Man\n",
      "None\n",
      "no\n",
      "1\n",
      "1700\n",
      "What is a person pushing a man off Boat Boat\n",
      "None\n",
      "yes\n",
      "5\n",
      "1800\n",
      "What is a man slicing Tomato Tomato\n",
      "None\n",
      "yes\n",
      "5\n",
      "1900\n",
      "What is a person creating a folder on Computer Computer screen\n",
      "None\n",
      "no\n",
      "3\n",
      "2000\n",
      "What is a boy adding juice in Cup Coffee mug\n",
      "None\n",
      "no\n",
      "2\n",
      "2100\n",
      "What is a man stirring in a bowl Mixture Sugar\n",
      "None\n",
      "no\n",
      "2\n",
      "2200\n",
      "Who is pouring coffee into a cup Person Man\n",
      "None\n",
      "yes\n",
      "5\n",
      "2300\n",
      "Who hammers a knife into a wooden board Man Man\n",
      "None\n",
      "yes\n",
      "5\n",
      "2400\n",
      "What is a woman playing with Rabbit Cat\n",
      "None\n",
      "no\n",
      "1\n",
      "2500\n",
      "What is playing a piano Someone Pianist\n",
      "None\n",
      "yes\n",
      "4\n",
      "2600\n",
      "Who is riding a motorcycle in the water at the edge of a beach Man Man\n",
      "None\n",
      "yes\n",
      "5\n",
      "2700\n",
      "What is a kitten doing Fail The kitten is playing in the kitchen.\n",
      "None\n",
      "no\n",
      "3\n",
      "2800\n",
      "Who dries off a woman Man Man\n",
      "None\n",
      "yes\n",
      "5\n",
      "4200\n",
      "What is a man doing Operate Point\n",
      "None\n",
      "no\n",
      "2\n",
      "4300\n",
      "What are a large group of men and women doing Dance Dancing\n",
      "None\n",
      "yes\n",
      "5\n",
      "4400\n",
      "What is a woman in a teacup being bombarded with by a bigger man Sugar Nothing\n",
      "None\n",
      "no\n",
      "1\n",
      "4500\n",
      "What does a person pour cooking into a pot Oil Olive oil\n",
      "None\n",
      "yes\n",
      "4\n",
      "4600\n",
      "Who is pouring tomato sauce from a can into a saucepan containing meat pieces Someone Chef\n",
      "None\n",
      "no\n",
      "2\n",
      "4700\n",
      "What does a man put on a plate of spaghetti Tomato Spaghetti sauce\n",
      "None\n",
      "yes\n",
      "4\n",
      "4800\n",
      "Who is being pulling into a lake Woman Woman\n",
      "None\n",
      "yes\n",
      "5\n",
      "4900\n",
      "What is showing fight stunts Monkey Fight stunts\n",
      "None\n",
      "no\n",
      "2\n",
      "5000\n",
      "What is getting a bath Hedgehog Hog\n",
      "None\n",
      "yes\n",
      "4\n",
      "5100\n",
      "What is a man playing Keyboard Piano\n",
      "None\n",
      "no\n",
      "3\n",
      "5200\n",
      "Who is playing guitar Man Man\n",
      "None\n",
      "yes\n",
      "5\n",
      "5300\n",
      "What are two men playing Tenni Ping pong\n",
      "None\n",
      "no\n",
      "1\n",
      "5400\n",
      "What was one man fought with another man who doing Try Drug dealing\n",
      "None\n",
      "no\n",
      "1\n",
      "5500\n",
      "What is the baby putting the dishes in Container Dishwasher\n",
      "None\n",
      "no\n",
      "3\n",
      "5600\n",
      "What is a woman doing Pet Holding cub\n",
      "None\n",
      "no\n",
      "3\n",
      "5700\n",
      "Who is making pancakes on a stove Man Man\n",
      "None\n",
      "yes\n",
      "5\n",
      "5800\n",
      "Who is spinning Woman Man\n",
      "None\n",
      "no\n",
      "1\n",
      "5900\n",
      "What is a person doing Slouse Cutting\n",
      "None\n",
      "no\n",
      "2\n",
      "6000\n",
      "What is going down a slide Panda Polar bear\n",
      "None\n",
      "no\n",
      "3\n",
      "6100\n",
      "What is a chef rolling Dough Dough\n",
      "None\n",
      "yes\n",
      "5\n",
      "6200\n",
      "Who is cutting meat with axe Man Man\n",
      "None\n",
      "yes\n",
      "5\n",
      "6300\n",
      "What did the pet store worker put into the box Lizard Rodent\n",
      "None\n",
      "no\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "answers = []\n",
    "scores = []\n",
    "for ind, elem in enumerate(pred_contents):\n",
    "    question = elem['q'][0].split('?')[0]\n",
    "    answer = elem['real']\n",
    "    pred = elem['a']\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \n",
    "                                \"You are an intelligent chatbot designed for evaluating the correctness of generative outputs for question-answer pairs. \"\n",
    "                                \"Your task is to compare the predicted answer with the correct answer and determine if they match meaningfully. Here's how you can accomplish the task:\"\n",
    "                                \"------\"\n",
    "                                \"##INSTRUCTIONS: \"\n",
    "                                \"- Focus on the meaningful match between the predicted answer and the correct answer.\\n\"\n",
    "                                \"- Consider synonyms or paraphrases as valid matches.\\n\"\n",
    "                                \"- Evaluate the correctness of the prediction compared to the answer.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\":\n",
    "                                \"Please evaluate the following video-based question-answer pair:\\n\\n\"\n",
    "                                f\"Question: {question}\\n\"\n",
    "                                f\"Correct Answer: {answer}\\n\"\n",
    "                                f\"Predicted Answer: {pred}\\n\\n\"\n",
    "                                \"Provide your evaluation only as a yes/no and score where the score is an integer value between 0 and 5, with 5 indicating the highest meaningful match. \"\n",
    "                                \"Please generate the response in the form of a Python dictionary string with keys 'pred' and 'score', where value of 'pred' is  a string of 'yes' or 'no' and value of 'score' is in INTEGER, not STRING.\"\n",
    "                                \"DO NOT PROVIDE ANY OTHER OUTPUT TEXT OR EXPLANATION. Only provide the Python dictionary string. \"\n",
    "                                \"For example, your response should look like this: {'pred': 'yes', 'score': 4.8}.\"\n",
    "                        }\n",
    "                    ]\n",
    "    )\n",
    "    # Convert response to a Python dictionary.\n",
    "    if (ind%100 ==0):\n",
    "        print (ind)\n",
    "        print (print (question, answer, pred))\n",
    "        print (ast.literal_eval(completion.choices[0].message.content)['pred'])\n",
    "        print (ast.literal_eval(completion.choices[0].message.content)['score'])\n",
    "    answers.append(ast.literal_eval(completion.choices[0].message.content)['pred'])\n",
    "    scores.append(ast.literal_eval(completion.choices[0].message.content)['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20d10fab-9ed1-432c-bca4-4f8eb24009fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gpt_answers.pkl', 'wb') as f:\n",
    "        pickle.dump(answers, f)\n",
    "with open('gpt_scores.pkl', 'wb') as f:\n",
    "        pickle.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e241eb3f-1792-4102-bea6-e14165b66e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.240625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cb66dc1-c9e3-4393-b895-8799d69dd1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49e1aac7-51af-4211-a5d3-7d15760c163e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4925"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_sum = 0\n",
    "count = 0\n",
    "yes_count = 0\n",
    "no_count = 0\n",
    "for pred in answers:\n",
    "    if \"yes\" in pred.lower():\n",
    "        yes_count += 1\n",
    "    elif \"no\" in pred.lower():\n",
    "        no_count += 1\n",
    "\n",
    "\n",
    "accuracy = yes_count / (yes_count + no_count)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab0159d6-ad72-4138-93b7-f828fdc97f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Hello, I'm working, I'm cool!\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "\n",
    "# socks5://proxxxyuser:proxypassuser@193.124.46.176\n",
    "client = OpenAI(\n",
    "    http_client=httpx.Client(proxy=\"socks5://fb_lab:T2wO4gqgumHs@193.124.46.176:8080\"),\n",
    "    api_key=\"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\".encode('ascii', 'ignore').decode('ascii'))\n",
    "\n",
    "gpt_user_prompt = 'Переведи на английский предложение \"Привет, я работаю, я крутой!\".'\n",
    "gpt_assistant_prompt = \"Ты вежливый ассистент, твоя задача - выполнять задания, которые у теебя просят выполнить.\"\n",
    "gpt_prompt = gpt_assistant_prompt, gpt_user_prompt\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"assistant\", \"content\": gpt_assistant_prompt}, {\"role\": \"user\", \"content\": gpt_user_prompt}],\n",
    "    temperature=0.0,\n",
    "    max_tokens=10,\n",
    "    frequency_penalty=0.0)\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c9ee066-a840-4a76-bc03-01bdec36fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENAI_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3478be10-c738-46dd-8d0a-20668475bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from openai==0.28) (4.67.0)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from openai==0.28) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.60.0\n",
      "    Uninstalling openai-1.60.0:\n",
      "      Successfully uninstalled openai-1.60.0\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caaf3e76-1863-4151-a05a-e6eca018631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: httpx[socks] in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (0.27.2)\n",
      "Requirement already satisfied: anyio in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (1.3.1)\n",
      "Collecting socksio==1.* (from httpx[socks])\n",
      "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpcore==1.*->httpx[socks]) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from anyio->httpx[socks]) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from anyio->httpx[socks]) (4.12.2)\n",
      "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: socksio\n",
      "Successfully installed socksio-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install httpx[socks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62a1a1-b79e-4409-8507-186403997cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-video_vika]",
   "language": "python",
   "name": "conda-env-.mlspace-video_vika-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

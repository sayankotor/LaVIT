{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06450f1b-0e49-4492-94c8-174dae7c6c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, a young man named Jack was traveling through the woods. He stumbled upon a clearing where a group of fairies were holding a party. The fairies invited Jack to join them, and he happily accepted.\n",
      "\n",
      "As the night went on, Jack saw that the fairies were\n",
      "You can call me Vicuna, and I was trained by Large Model Systems Organization (LMSYS) researchers as a language model.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"EMPTY\"\n",
    "openai.base_url = \"http://localhost:8000/v1/\"\n",
    "\n",
    "model = \"vicuna-13b-v1.5\"\n",
    "prompt = \"Once upon a time\"\n",
    "\n",
    "# create a completion\n",
    "completion = openai.completions.create(model=model, prompt=prompt, max_tokens=64)\n",
    "# print the completion\n",
    "print(prompt + completion.choices[0].text)\n",
    "\n",
    "# create a chat completion\n",
    "completion = openai.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Hello! What is your name?\"}]\n",
    ")\n",
    "# print the completion\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfb4217-4068-4463-abd9-ecf1bd7f29ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00AD (3937343426.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    sk-proj-psRNAKc9xW_I5RU4KvwR1HkG04QfleWNOmuLEJS080muDLEb_EepFZLq08OY­JnWCRYeIfpeQgjT3BlbkFJrKymouCGWgVYcZY2YUGJFYzbFB5qI4n_NUOlxl­qfJKK6ThhwyQAO8hK7zaJvrwHYl6p6sP2MYA\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00AD\n"
     ]
    }
   ],
   "source": [
    "sk-proj-psRNAKc9xW_I5RU4KvwR1HkG04QfleWNOmuLEJS080muDLEb_EepFZLq08OY­JnWCRYeIfpeQgjT3BlbkFJrKymouCGWgVYcZY2YUGJFYzbFB5qI4n_NUOlxl­qfJKK6ThhwyQAO8hK7zaJvrwHYl6p6sP2MYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0903fa-6ac0-4b5c-a046-42ad8ff3ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file = open(\"sample_set.json\")\n",
    "pred_contents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea087e6-95f5-4032-b53a-c84f59c537b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': ['Who pours liquid from a plastic container into a ziploc bag containing meat pieces? Answer the question using a single word or a short phrase with multiple words.'],\n",
       " 'real': 'Someone',\n",
       " 'a': 'Man'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f326ec3a-c9d9-4eeb-bf6f-263692eef1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c0fe99-d84d-4fdc-a7fe-028cdc49188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = pred_contents[0]['q'][0].split('?')[0] + '?'\n",
    "answer = pred_contents[0]['real']\n",
    "pred = pred_contents[0]['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3fa20d-604c-4f0d-8f62-17b5589aab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who pours liquid from a plastic container into a ziploc bag containing meat pieces? Someone Man\n"
     ]
    }
   ],
   "source": [
    "print (question, answer, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89283ee5-2817-4244-886c-de35e6197329",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "completion = openai.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \n",
    "                                \"You are an intelligent chatbot designed for evaluating the correctness of generative outputs for question-answer pairs. \"\n",
    "                                \"Your task is to compare the predicted answer with the correct answer and determine if they match meaningfully. Here's how you can accomplish the task:\"\n",
    "                                \"------\"\n",
    "                                \"##INSTRUCTIONS: \"\n",
    "                                \"- Focus on the meaningful match between the predicted answer and the correct answer.\\n\"\n",
    "                                \"- Consider synonyms or paraphrases as valid matches.\\n\"\n",
    "                                \"- Evaluate the correctness of the prediction compared to the answer.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\":\n",
    "                                \"Please evaluate the following video-based question-answer pair:\\n\\n\"\n",
    "                                f\"Question: {question}\\n\"\n",
    "                                f\"Correct Answer: {answer}\\n\"\n",
    "                                f\"Predicted Answer: {pred}\\n\\n\"\n",
    "                                \"Provide your evaluation only as a yes/no and score, where the evaluation is 'yes' if the Predicted Answer and Correct Answer have the same meaning in the context of the Question, 'no' in other cases; the score is an integer value between 0 and 5, with 5 indicating the highest meaningful match. \"\n",
    "                                \"Please generate the response in the form of a Python dictionary string with keys 'pred' and 'score', where value of 'pred' is a string of 'yes' or 'no' and value of 'score' is in INTEGER, not STRING.\"\n",
    "                                \"DO NOT PROVIDE ANY OTHER OUTPUT TEXT OR EXPLANATION. Only provide the Python dictionary string. \"\n",
    "                                \"For example, your response should look like this: {'pred': 'yes', 'score': 4.8}.\"\n",
    "                        }\n",
    "                    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8653cdbf-6b21-4552-8e08-0670285dc5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-LsUvCzi2mro6tQDupcR62o', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"{'pred': 'yes','score': 4.5}\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738743106, model='vicuna-13b-v1.5', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=14, prompt_tokens=342, total_tokens=356, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16607e80-49f2-4622-b7a9-b3d13865a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval(completion.choices[0].message.content)['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0372a05c-a1e7-4459-9f6a-e72a65611159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(completion.choices[0].message.content)['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db357a7-ba54-4d01-b894-b9946d5bd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Who pours liquid from a plastic container into a ziploc bag containing meat pieces? Someone Man\n",
      "None\n",
      "no\n",
      "3.0\n",
      "100\n",
      "Who caught a ball? Man Catcher\n",
      "None\n",
      "no\n",
      "3\n",
      "200\n",
      "Who is hanging on a vine? Woman Cat\n",
      "None\n",
      "no\n",
      "1\n",
      "300\n",
      "What does a man operate remote control car through? Office Window\n",
      "None\n",
      "no\n",
      "2.8\n",
      "400\n",
      "What is a young boy playing? Piano Piano\n",
      "None\n",
      "yes\n",
      "5.0\n",
      "1000\n",
      "Who petting a beaver? Someone Hand\n",
      "None\n",
      "no\n",
      "1.5\n",
      "1100\n",
      "What is a flight attendant closing the emergency door of? Plane Plane\n",
      "None\n",
      "yes\n",
      "5.0\n",
      "1700\n",
      "What is a person pushing a man off? Boat Ship\n",
      "None\n",
      "no\n",
      "2.5\n",
      "1800\n",
      "What is a man slicing? Tomato Tomato\n",
      "None\n",
      "yes\n",
      "5.0\n",
      "1900\n",
      "What is a person creating a folder on? Computer Computer\n",
      "None\n",
      "yes\n",
      "5.0\n",
      "2500\n",
      "What is playing a piano? Someone Candles\n",
      "None\n",
      "no\n",
      "1.2\n",
      "2600\n",
      "Who is riding a motorcycle in the water at the edge of a beach? Man Man\n",
      "None\n",
      "yes\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "answers = []\n",
    "scores = []\n",
    "for ind, elem in enumerate(pred_contents):\n",
    "    question = elem['q'][0].split('?')[0] + '?'\n",
    "    answer = elem['real']\n",
    "    pred = elem['a']\n",
    "    \n",
    "    completion = openai.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \n",
    "                                \"You are an intelligent chatbot designed for evaluating the correctness of generative outputs for question-answer pairs. \"\n",
    "                                \"Your task is to compare the predicted answer with the correct answer and determine if they match meaningfully. Here's how you can accomplish the task:\"\n",
    "                                \"------\"\n",
    "                                \"##INSTRUCTIONS: \"\n",
    "                                \"- Focus on the meaningful match between the predicted answer and the correct answer.\\n\"\n",
    "                                \"- Consider synonyms or paraphrases as valid matches.\\n\"\n",
    "                                \"- Evaluate the correctness of the prediction compared to the answer.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\":\n",
    "                                \"Please evaluate the following video-based question-answer pair:\\n\\n\"\n",
    "                                f\"Question: {question}\\n\"\n",
    "                                f\"Correct Answer: {answer}\\n\"\n",
    "                                f\"Predicted Answer: {pred}\\n\\n\"\n",
    "                                \"Provide your evaluation only as a yes/no and score, where the evaluation is 'yes' if the Predicted Answer and Correct Answer have the same meaning in the context of the Question, 'no' in other cases; the score is an integer value between 0 and 5, with 5 indicating the highest meaningful match. \"\n",
    "                                \"Please generate the response in the form of a Python dictionary string with keys 'pred' and 'score', where value of 'pred' is a string of 'yes' or 'no' and value of 'score' is in INTEGER, not STRING.\"\n",
    "                                \"DO NOT PROVIDE ANY OTHER OUTPUT TEXT OR EXPLANATION. Only provide the Python dictionary string. \"\n",
    "                                \"For example, your response should look like this: {'pred': 'yes', 'score': 4.8}.\"\n",
    "                        }\n",
    "                    ]\n",
    "    )\n",
    "    # Convert response to a Python dictionary.\n",
    "    if (ind%100 ==0):\n",
    "        print (ind)\n",
    "        print (print (question, answer, pred))\n",
    "        print (ast.literal_eval(completion.choices[0].message.content)['pred'])\n",
    "        print (ast.literal_eval(completion.choices[0].message.content)['score'])\n",
    "    try:\n",
    "        answers.append(ast.literal_eval(completion.choices[0].message.content)['pred'])\n",
    "        scores.append(ast.literal_eval(completion.choices[0].message.content)['score'])\n",
    "    except:\n",
    "        answers.append(ast.literal_eval(completion.choices[0].message.content.split(\"\\n\\nExplanation\")[0])['pred'])\n",
    "        scores.append(ast.literal_eval(completion.choices[0].message.content.split(\"\\n\\nExplanation\")[0])['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd181d80-282f-4793-a02a-466115d86f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-HoaeA5JeuJfR5Vobtetuys', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"pred\": \"yes\", \"score\": 5}\\n\\nExplanation:\\nThe Predicted Answer and Correct Answer have the same meaning in the context of the question, and the match is meaningful. Therefore, the evaluation is \\'yes\\', and the score is 5, which indicates the highest meaningful match.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738712394, model='vicuna-13b-v1.5', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=67, prompt_tokens=331, total_tokens=398, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0fce8dd-a5b6-4afe-b668-868f0da587f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 3)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.mlspace/envs/video_vika/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[22], line 1\u001b[0m\n    ast.literal_eval(completion.choices[0].message.content)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.mlspace/envs/video_vika/lib/python3.10/ast.py:64\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/.mlspace/envs/video_vika/lib/python3.10/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Explanation:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ast.literal_eval(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce058e79-3363-4e9f-a750-93ea0e1219e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(completion.choices[0].message.content.split(\"\\n\\nExplanation\")[0])['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1686d3-4770-439a-96ae-9d2f6aa7ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is a person pushing a man off? Boat Ship\n",
    "None\n",
    "no\n",
    "3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb80d6d-d594-45b6-be01-e65615cfe94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6052"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38587b79-1ea3-4996-b1c6-4fba8a39af0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e64fd6d-723f-4d53-bc3e-dfc725a9d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"gpt_answers.pkl\",'rb')\n",
    "answers_gpt = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b676a21-d1ed-4a1d-804f-71f7501502d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f3503c-8dec-4d8e-bbf1-e93ab64f6e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_gpt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a47533f-f088-4680-a4e4-c345121b1918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41490509211690907"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cohen_kappa_score(answers, answers_gpt[:len(answers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d10fab-9ed1-432c-bca4-4f8eb24009fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vicunia7B_answers.pkl', 'wb') as f:\n",
    "        pickle.dump(answers, f)\n",
    "with open('vicunia7B_scores.pkl', 'wb') as f:\n",
    "        pickle.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e241eb3f-1792-4102-bea6-e14165b66e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4104841374752146"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cb66dc1-c9e3-4393-b895-8799d69dd1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'false',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49e1aac7-51af-4211-a5d3-7d15760c163e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4390284203569068"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_sum = 0\n",
    "count = 0\n",
    "yes_count = 0\n",
    "no_count = 0\n",
    "for pred in answers:\n",
    "    if \"yes\" in pred.lower():\n",
    "        yes_count += 1\n",
    "    elif \"no\" in pred.lower():\n",
    "        no_count += 1\n",
    "\n",
    "\n",
    "accuracy = yes_count / (yes_count + no_count)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab0159d6-ad72-4138-93b7-f828fdc97f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Hello, I'm working, I'm cool!\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "\n",
    "# socks5://proxxxyuser:proxypassuser@193.124.46.176\n",
    "client = OpenAI(\n",
    "    http_client=httpx.Client(proxy=\"socks5://fb_lab:T2wO4gqgumHs@193.124.46.176:8080\"),\n",
    "    api_key=\"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\".encode('ascii', 'ignore').decode('ascii'))\n",
    "\n",
    "gpt_user_prompt = 'Переведи на английский предложение \"Привет, я работаю, я крутой!\".'\n",
    "gpt_assistant_prompt = \"Ты вежливый ассистент, твоя задача - выполнять задания, которые у теебя просят выполнить.\"\n",
    "gpt_prompt = gpt_assistant_prompt, gpt_user_prompt\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"assistant\", \"content\": gpt_assistant_prompt}, {\"role\": \"user\", \"content\": gpt_user_prompt}],\n",
    "    temperature=0.0,\n",
    "    max_tokens=10,\n",
    "    frequency_penalty=0.0)\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c9ee066-a840-4a76-bc03-01bdec36fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENAI_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3478be10-c738-46dd-8d0a-20668475bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from openai==0.28) (4.67.0)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from openai==0.28) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.60.0\n",
      "    Uninstalling openai-1.60.0:\n",
      "      Successfully uninstalled openai-1.60.0\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caaf3e76-1863-4151-a05a-e6eca018631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: httpx[socks] in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (0.27.2)\n",
      "Requirement already satisfied: anyio in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpx[socks]) (1.3.1)\n",
      "Collecting socksio==1.* (from httpx[socks])\n",
      "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from httpcore==1.*->httpx[socks]) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from anyio->httpx[socks]) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /home/jovyan/.mlspace/envs/video_vika/lib/python3.10/site-packages (from anyio->httpx[socks]) (4.12.2)\n",
      "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: socksio\n",
      "Successfully installed socksio-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install httpx[socks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62a1a1-b79e-4409-8507-186403997cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-video_vika]",
   "language": "python",
   "name": "conda-env-.mlspace-video_vika-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
